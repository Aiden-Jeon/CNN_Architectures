{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader, sampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from models import AlexNet, VGGNet, GoogLeNet\n",
    "from utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset(m):\n",
    "    if hasattr(m, 'reset_parameters'):\n",
    "        m.reset_parameters()\n",
    "\n",
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements sequentially from some offset. \n",
    "    Arguments:\n",
    "        num_samples: # of desired datapoints\n",
    "        start: offset where we should start selecting from\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples, start = 0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.start, self.start + self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "cifar10_train = dset.CIFAR10('data/', train=True, download=True, \n",
    "                             transform=transform)\n",
    "cifar10_test = dset.CIFAR10('data/', train=False, download=True, \n",
    "                            transform=transform)\n",
    "NUM_TRAIN = 49000\n",
    "NUM_VAL = 1000\n",
    "\n",
    "train_loader = DataLoader(cifar10_train, batch_size=64, \n",
    "                          sampler=ChunkSampler(NUM_TRAIN, 0))\n",
    "val_loader = DataLoader(cifar10_train, batch_size=64, \n",
    "                        sampler=ChunkSampler(NUM_VAL, NUM_TRAIN))\n",
    "test_loader = DataLoader(cifar10_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = AlexNet.AlexNet(10, dtype)\n",
    "alexnet_loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
    "alexnet_optimizer = optim.Adam(alexnet.parameters(),lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(5, 5))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.random.manual_seed(12345)\n",
    "alexnet.apply(reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_trainer = utils.trainier(alexnet, alexnet_optimizer, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 => Time: 31.65sec, Train avg loss: 1.7859, train acc: 44.34%, val acc: 45.00%\n",
      "Epoch 2/10 => Time: 30.99sec, Train avg loss: 1.4201, train acc: 52.89%, val acc: 52.20%\n",
      "Epoch 3/10 => Time: 30.61sec, Train avg loss: 1.2540, train acc: 58.16%, val acc: 54.80%\n",
      "Epoch 4/10 => Time: 29.99sec, Train avg loss: 1.1332, train acc: 62.59%, val acc: 57.20%\n",
      "Epoch 5/10 => Time: 30.05sec, Train avg loss: 1.0203, train acc: 66.38%, val acc: 59.90%\n",
      "Epoch 6/10 => Time: 29.59sec, Train avg loss: 0.9084, train acc: 69.83%, val acc: 59.40%\n",
      "Epoch 7/10 => Time: 29.99sec, Train avg loss: 0.7991, train acc: 72.37%, val acc: 60.80%\n",
      "Epoch 8/10 => Time: 30.12sec, Train avg loss: 0.7173, train acc: 73.38%, val acc: 58.90%\n",
      "Epoch 9/10 => Time: 30.08sec, Train avg loss: 0.6373, train acc: 76.42%, val acc: 59.40%\n",
      "Epoch 10/10 => Time: 30.12sec, Train avg loss: 0.5478, train acc: 79.86%, val acc: 60.40%\n"
     ]
    }
   ],
   "source": [
    "alexnet_trainer.train(10, alexnet_loss_fn, train_loader, val_loader, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGGNet11(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vggnet = VGGNet.VGGNet11(10, dtype)\n",
    "vggnet_loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
    "vggnet_optimizer = optim.Adam(vggnet.parameters(),lr=1e-4)\n",
    "torch.cuda.random.manual_seed(12345)\n",
    "vggnet.apply(reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vggnet_trainer = utils.trainier(vggnet, vggnet_optimizer, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 => Time: 35.78sec, Train avg loss: 1.7181, train acc: 47.35%, val acc: 49.00%\n",
      "Epoch 2/10 => Time: 36.08sec, Train avg loss: 1.3030, train acc: 59.24%, val acc: 59.80%\n",
      "Epoch 3/10 => Time: 37.01sec, Train avg loss: 1.0878, train acc: 65.30%, val acc: 63.30%\n",
      "Epoch 4/10 => Time: 36.25sec, Train avg loss: 0.9309, train acc: 70.05%, val acc: 65.30%\n",
      "Epoch 5/10 => Time: 36.66sec, Train avg loss: 0.7994, train acc: 76.06%, val acc: 68.60%\n",
      "Epoch 6/10 => Time: 36.42sec, Train avg loss: 0.6818, train acc: 79.07%, val acc: 71.00%\n",
      "Epoch 7/10 => Time: 37.16sec, Train avg loss: 0.5793, train acc: 81.18%, val acc: 70.80%\n",
      "Epoch 8/10 => Time: 37.28sec, Train avg loss: 0.4818, train acc: 84.15%, val acc: 71.30%\n",
      "Epoch 9/10 => Time: 37.12sec, Train avg loss: 0.3983, train acc: 85.24%, val acc: 70.80%\n",
      "Epoch 10/10 => Time: 36.99sec, Train avg loss: 0.3273, train acc: 85.09%, val acc: 71.30%\n"
     ]
    }
   ],
   "source": [
    "vggnet_trainer.train(10, vggnet_loss_fn, train_loader, val_loader, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
